{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzeZrsy4l0_c",
    "outputId": "17dfef1e-678e-41a0-aac4-83358f84fe79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLNnOgr0mKEF",
    "outputId": "ca15b81c-f497-49ea-bd17-82c9afcbe67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: datasets 3.5.0\n",
      "Uninstalling datasets-3.5.0:\n",
      "  Successfully uninstalled datasets-3.5.0\n",
      "Collecting git+https://github.com/huggingface/datasets.git\n",
      "  Cloning https://github.com/huggingface/datasets.git to /tmp/pip-req-build-avjvevfv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets.git /tmp/pip-req-build-avjvevfv\n",
      "  Resolved https://github.com/huggingface/datasets.git to commit ba451d1d9e99904a13413c087a2b01bf64f0e8d6\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.5.1.dev0) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.1.dev0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.1.dev0) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.1.dev0) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.1.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.1.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.1.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.1.dev0) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.1.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.1.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.1.dev0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.1.dev0) (1.17.0)\n",
      "Building wheels for collected packages: datasets\n",
      "  Building wheel for datasets (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for datasets: filename=datasets-3.5.1.dev0-py3-none-any.whl size=491554 sha256=5884d9918f1a1c45d39fecf12bf72c8a9d46032f9bda253d5af484375b74e176\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dpy8u3qh/wheels/33/07/5d/35c54571205e7fce2b7600c936fd1d5c558c1b7ea98e86e0e1\n",
      "Successfully built datasets\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-3.5.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y datasets\n",
    "!pip install git+https://github.com/huggingface/datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_ohLJmYmRVl",
    "outputId": "ca512e02-fdb9-4f66-d44b-4c1754ba1329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1.dev0\n",
      "/usr/local/lib/python3.11/dist-packages/datasets/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)\n",
    "print(datasets.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gL-P8t7rwGmi",
    "outputId": "9cb06d4d-1c1f-46d4-e3ef-8d14c311065a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639,
     "referenced_widgets": [
      "d08d794422244326b618cb5705c60f38",
      "b9570c452a914b3ba144d33ac59e32f9",
      "f894abab660d4be49b110c482abd37aa",
      "8b320d8225ef4e8189852f182cd45fae",
      "9ff95cec6f314bcb9403a5f25921fdc8",
      "76ccbd5637014ea5964dfddb9b3f4d29",
      "c13da44058424ddfa9e4147045ada96a",
      "65da0d62ecca40b690eaa4a9a95b4d8a",
      "c1e409d4ee394f5c8de62e20a3f2c97b",
      "1a07cad1059e477a938106549a8ad203",
      "78a052760bad472ba2950920568ab57a",
      "dfeeca2cec3c433e87a3be38c077cbb3",
      "85c06b66803345f3a17f9c34f284fd1d",
      "1ddf5f2e21ed42daaaef6f34d52cc928",
      "d3255b31377b4b47ac4538f47489d54d",
      "b3cdcf26b05d4458abebbd0fc8b4c066",
      "0b04604276e1422398fa11655735fbec",
      "22880894ffdd4829a27f327b6abbb3c5",
      "8a5e722e53014f4488730fee03ed7968",
      "9d7e20c8a63e44e8a66bbcd52df200e7",
      "8880dd4801a6439e976ba1af2820b3b4",
      "648d6e8c22e54935afbdd720c8867a1d"
     ]
    },
    "id": "fmbYiiGxmwq_",
    "outputId": "7ac71737-6730-4130-afca-c3027d0d2461"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08d794422244326b618cb5705c60f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeeca2cec3c433e87a3be38c077cbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c5863fe743e4>:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marunyasenadeera\u001b[0m (\u001b[33marunyasenadeera-asian-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250426_131838-h5f1446g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface/runs/h5f1446g' target=\"_blank\">./mT5-thai-finetuned-V4</a></strong> to <a href='https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface/runs/h5f1446g' target=\"_blank\">https://wandb.ai/arunyasenadeera-asian-institute-of-technology/huggingface/runs/h5f1446g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 16:02, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.910900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 84, 'num_beams': 4, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1080, training_loss=1.023371661150897, metrics={'train_runtime': 966.9459, 'train_samples_per_second': 1.117, 'train_steps_per_second': 1.117, 'total_flos': 1294969822248960.0, 'train_loss': 1.023371661150897, 'epoch': 8.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"formal_thai_augmented.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# Prepare the text by adding a prompt\n",
    "df[\"text\"] = \"Summarize this Thai military document carefully. Keep names, dates, locations, procedures accurate: \" + df[\"text\"]\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_checkpoint = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples[\"text\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "    output_dir=\"./mT5-thai-finetuned-V4\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "#trainer.save_model(\"./mT5-thai-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "1da6450cb3eb48d8afc01282e42ce582",
      "8430938094d44f9685c1aec2333b458f",
      "cd91307922d047d98f251ea33191dde0",
      "ecfaf0853a8741ee8b8685292b60738a",
      "4625351e1a994739b1fbc9a38ba8ecda",
      "8ac6ada649ca4c5c907c426c833afd77",
      "93ab36108aab4591a35089fc50b8ad95",
      "1b2f59ca1cd14a36846657c639e10ab2",
      "a869459b2da3432aab20d9605dc2ff0b",
      "cc747cc1eedb4f1fa6d0928de5c81d3f",
      "2a21a21a66d046ae95ad48711ef82dfa",
      "96e61c1b79c4427d8189818910bac39a",
      "930cfe7e695e45ae9faaeef41c7bb763",
      "23938875a21e435594bb01a1d38e185a",
      "8c70614c175744919544d582b8fc70bc",
      "0c80bdf3ca494f67b5916f283cb6ff64",
      "7181b47f30744bd5ba2319ad4d7a62bd",
      "eec650ee7d6b4b70b8b4ce6727fe67c5",
      "7737cc2143b64834a10dc2cc79982b56",
      "a05e8c5268f04a79a965d14a9f0a05b0"
     ]
    },
    "id": "p3cVW5PWw2Hm",
    "outputId": "ddfadbab-b30a-4d0c-bda0-800f13d016f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6450cb3eb48d8afc01282e42ce582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 10: LOGIN TO HUGGINGFACE (one time)\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "2ce83bdcda3545d083447e5253e9d3a9",
      "b3040cf291474f8ab87f93e54da2457e",
      "7f8304d29ccf4720ab0ed24a50110df3",
      "855a035c956042a0825f2a69c6c31c4d",
      "7ed55da6f49d4584b31be3a5a2a04113",
      "19106587fa4b40ce8bd4dc4d0d3711e5",
      "928a0f0765de49e2996775b965db01dc",
      "84f06f1add3e4367a53b58c9089e8ee4",
      "32e63bee519b49ceb9cf8f1a79ac611d",
      "39ef8b4d84bc41cdbc77b2fa51fc36fe",
      "2106b7a504dd4c88a126249b4bd17aa8",
      "c5c03a7e82aa491c9903b7ad857db5a6",
      "98872eceb82f4e8cb47e41840182dff9",
      "495081c11c7b41b1b5c6ab03358bd1da",
      "cd20339a21f0438b8d5f2972970d2979",
      "cc4962577c604fe989d4c9e30646c67a",
      "fa6d198185ea4018a9075962b95b0524",
      "d47a3b36eb4241fd80628e185c69c7f1",
      "934a09ecb7ce47c28c222d92a251940d",
      "26e95785732f4cd48e5c1cd84606189b",
      "9d4026cfc7b6496f9abe490a776af28a",
      "90d956b91b054c078debea4607046612",
      "ba7bd9c94f6a46c1a73b3d7c28037473",
      "09e296f6226849c580b146d0734269ee",
      "05634d3c03aa4380ac9f3f7bdc30e865",
      "48d6cdca1600422e8d799fd8f7f8ffe9",
      "31a3606fdecf45f1abfa6dab1afcb4fb",
      "df632935d6504470bb4ba9563628dead",
      "fb4bd24d32454fae8bf54f0923baf6b2",
      "ac276a72b2894dee8c1501daefa39a55",
      "9ae5fe2f1cb64c5598b799d38e7bba4e",
      "72ba329037094277bef6ed848003e89d",
      "b0779a3c5105455d83eb15652097d716",
      "8f20bf3a4c344998be97213c5b79d631",
      "b9cff5cff0cf403e96dedbfd02848bd2",
      "52726e1a6ee34d4297704ce75f2b8ecc",
      "3c2edba47b5e4bf1a223e3be0c880238",
      "50867858a04b4625b25bcb80bc6b53da",
      "635f5b67f09e41c9bb0be91bff2e9733",
      "64ed4c0c98604b07ae148555809a4381",
      "34aecd2f5a2e405097a1316a04f98841",
      "e29a313c908547f9aaece026e7dbb35f",
      "e05ddebe3fd14960abaceb19db4ea1a8",
      "1d6d41d4c0114fa59d152a0c09f756a2",
      "b5106934fded4a308662220eaba0a7d6",
      "4f0261c3c04d42caaa527d692163cddd",
      "476c7d84a9b447f88e93ed15a4226701",
      "f0b2542b9bd74702a45637a1339bda15",
      "931ec83481e24f8baa7eb8e11198539a",
      "cc9ab2f8b7504250a1e6111be9b4570c",
      "0fcef73bd9144d0ba0bdfa9e3b2fc492",
      "2831bea369df494e92e46ab10e68149b",
      "ef4fa0e8dd814e44a1cfbcb0fa73b580",
      "699cbc9c97ac41b6bb0dbeb1bc2e091d",
      "03977f4509404aefbae788b19247bc6b"
     ]
    },
    "id": "IBWnvEKdw6l0",
    "outputId": "de29c46a-ca69-45d6-b5e4-383157973f14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce83bdcda3545d083447e5253e9d3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c03a7e82aa491c9903b7ad857db5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7bd9c94f6a46c1a73b3d7c28037473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f20bf3a4c344998be97213c5b79d631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5106934fded4a308662220eaba0a7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully uploaded to Hugging Face Hub under: mT5-thai-summarization-finetuned-v4\n"
     ]
    }
   ],
   "source": [
    "# STEP 11: UPLOAD MODEL TO HUGGINGFACE HUB\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "repo_name = \"mT5-thai-summarization-finetuned-v4\"  # you can change the name\n",
    "\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)\n",
    "\n",
    "print(f\"✅ Successfully uploaded to Hugging Face Hub under: {repo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets": [
      "b94a86056317451db8ffae5f22b3f149",
      "af9f4ef3d17f456abc4526b1dd499d0a",
      "9192222e184540448c33fd9d64cec261",
      "eb9f4ab5d4154a08a2ded9cfb23ae835",
      "7a339435de68460fb66d9e0192cfa593",
      "46321439cc184a9dbb22d5e2d4eefc61",
      "15c81a02ae5040db98860946e2afc274",
      "c9f43433b40149619baced7e9d3aa2da",
      "5a9f4f07e71b454ba3306689c330a59b",
      "23229075bf794c9388c2f94207644e96",
      "d3ffce43fd8a4d818bb6b381aa158e74",
      "eec1946de0404d83a6e9d3b6f674cb99",
      "174955d0e95a497c97ad219b32e356c5",
      "e4433d3032354d92a69117c62c0fbda9",
      "8168db076ea540059b474302e177a266",
      "b1228ad39d27490f8fa2f933ff690133",
      "989c530f88c64e778cdc36915e88a7c3",
      "6e9b1bdc923940b5a98a94cef243aa9c",
      "194a336369d24428a71c6562eb095780",
      "fa262edf7ca8474a98ef0c560833a741",
      "f27aa54a01f44ada9d4ac3cbebe74cac",
      "b0422c746a6a4f279e70e62aff026b2f",
      "cd2d0b1aa90a4caca8ebd6a1a9084f51",
      "b2725152b00848af8960b52f1bd87942",
      "8a1f5d8f74d84444957948e500db8d2b",
      "715eab484bdf4ca6ab7182751ee84c7a",
      "130985276f1140a9bb9aa378bad47a56",
      "8157d67577bc4e87bc333b95a17a07ec",
      "3172cc6154e448d986b6435f02dcbf4b",
      "4c4cc29fe5c34f52a0d3d323d60f3b66",
      "b68419a4329449f899f6414e5a6a6713",
      "d16c674273374d629d6564e817972c1c",
      "c66119f308b84509912e6703a544589d",
      "82754d32184843369c23ff3031acacb0",
      "5794297fa0044a179577b891b6aca8bd",
      "29539953886a4fe1b4ec59bed69af158",
      "b372f75e2cb04ae29592799a879f826b",
      "1504f3c2cca54cdc8f70ce59bfbbaf2d",
      "b8dae4b8798842309d060e9481bdeff1",
      "3c880442beef494a9562b2a96c6f2047",
      "d7a9cb2862ff462782cc358663182550",
      "691aa1c2beae4a66a95e7b0f07f4e4e7",
      "e04a8df081ee4b1a81c3973f485f0711",
      "fec5818bae8b405189f4eebed164d562",
      "f098e1bc11874662963ad7e2a4b36495",
      "1eacca5658d84adfb85800ae152eed79",
      "28edb5c35bde4d55800495ef15bd0bb3",
      "c8df74b4d1144348922f2d59f00b9346",
      "f1b179c28186487da13ed048ba7b2d0a",
      "e275d0c71cac45e0b76a1870876e76ba",
      "39c5ffbab1e64dc7b1ea562a2f073509",
      "9773aceb970942f995f249c2dfb3bee0",
      "05293ac3374f45ec8825430aaf40a6e6",
      "032de81124dd44a0b9be6d63ee33a814",
      "1c5c046442694f15ba16741151019487",
      "7a6f885529424335a2a13751fdfc314a",
      "30d967b2c1b0478d931bad4c61ef6d01",
      "807a673c15004b7386fa2f4087c0a7e1",
      "9b918c59b6cc4262b4408cdad933b8b5",
      "5483ae75424a4787a62ef00b791e066b",
      "28c41160edbe451381a97d3241396ed5",
      "98056cb16e104b26af202cb5279a4e90",
      "389969b68d684a6e8d3b70051a03686c",
      "e7dd17151b6b41518db0cb3d7ecd217a",
      "0a5649750d59475ab91645e0b155269d",
      "4004a9a514d14377bd4415dfd88da6db",
      "d61bf60688984abea2c3f2c4ea4ad461",
      "80cabc2cb57544a08250354ceff336e9",
      "20bf417ff273418786e70c78871b73f4",
      "d1a55133562f4b28b86dcfe2ec76a12a",
      "2d42c39c62f54f84b8abcdb7210344b5",
      "62e39da130d645bd846ff2f61693337b",
      "a7ef7144b286469a95363fac2c9408e5",
      "d43f4d76583543bbb19718be51669707",
      "a115eac3f8a2479792bb86d8f98cd44e",
      "630dd2a2abdb45cbb061a93dbabefae8",
      "1ade15f6a1554215809ac1e4b4cb6b3f"
     ]
    },
    "id": "AtfuRai70WK0",
    "outputId": "65496ad5-2155-4077-c466-0774b77cbe10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94a86056317451db8ffae5f22b3f149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/19.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec1946de0404d83a6e9d3b6f674cb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2d0b1aa90a4caca8ebd6a1a9084f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82754d32184843369c23ff3031acacb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f098e1bc11874662963ad7e2a4b36495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6f885529424335a2a13751fdfc314a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61bf60688984abea2c3f2c4ea4ad461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Summary:\n",
      " กทด.บก.สปท. ขอนัดหมายประชุมเพื่อเก็บรวบรวมข้อมูลและความต้องการใช้งานระบบ Learning Management System และ Online course ในห้วงเดือน มิ.ย.-ก.ค. 67 รายละเอียดตาม QR Code ที่แนบ\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"arunyasenadeera/mT5-thai-summarization-finetuned-v4\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Strong summarization function (no post-fix)\n",
    "def strong_summarize(text, max_input_length=512, max_output_length=700):\n",
    "    instruction = (\n",
    "        \"โปรดสรุปข้อความต่อไปนี้อย่างกระชับและชัดเจน \"\n",
    "        \"รักษาข้อมูลสำคัญให้ครบถ้วน เช่น ชื่อบุคคล ตำแหน่ง หน่วยงาน สถานที่ วันเดือนปี \"\n",
    "        \"ห้ามเปลี่ยนแปลงข้อเท็จจริง ห้ามเพิ่มเนื้อหาใหม่ และห้ามตัดข้อมูลสำคัญ \"\n",
    "        \"ห้ามละข้อมูลที่เกี่ยวกับการประชุม การเตรียมการ และภารกิจสนับสนุนที่สำคัญ \"\n",
    "        \"ใช้ภาษาทางการที่เหมาะสมสำหรับรายงานราชการ.\"\n",
    "    )\n",
    "\n",
    "    input_text = instruction + \"\\n\\n\" + text\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "        padding=\"longest\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_output_length,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "your_text = \"\"\"\n",
    "สปท. (กทด.บก.สปท.) ได้จัดทํา “งานจ้างพัฒนาระบบ Learning Management System และ Online Course” ตามโครงการพัฒนาโครงสร้างพื้นฐานด้านเทคโนโลยีสารสนเทศของ สส.ทหาร ประจําปี งบประมาณ พ.ศ. 2567 ซึ่งเป็นงานดําเนินงานตามสถาปัตยกรรมองค์กร บก.ทท. (RTARF EA) ประจําปี งบประมาณ พ.ศ. 2567 เพื่อใช้ในการสนับสนุนการจัดการศึกษาที่ส่งเสริมการเรียนรู้เชิงรุกให้กับหลักสูตรต่าง ๆ ของ บก.ทท. และ เหล่าทัพ รวมทั้งเพื่อเป็นศูนย์กลางในการเชื่อมต่อข้อมูลด้านการศึกษาและเปิดเผยข้อมูล ด้านการศึกษาตามหลักธรรมาภิบาลข้อมูลภาครัฐ โดยในปัจจุบันได้มีการดําเนินงานจนถึงขั้นตอน การพิจารณาคัดเลือกได้ บริษัท เพอร์เฟคคอมพิวเตอร์โซลูชัน จํากัด เป็นผู้รับจ้างพัฒนาระบบงานฯ ดังกล่าว  เพื่อให้การดําเนินงานเป็นไปด้วยความเรียบร้อย สปท. (กทด.บก.สปท.) จึงขอนัดหมายประชุมเพื่อเก็บรวบรวมข้อมูลและความต้องการใช้งานระบบฯ ในห้วงเดือน มิ.ย.-ก.ค. 67 รายละเอียดตาม QR Code ที่แนบ โดยให้ บริษัท เพอร์เฟคคอมพิวเตอร์โซลูชัน จํากัด ได้เข้าร่วมประชุมฯ หารือและเก็บรวบรวมข้อมูลและความต้องการใช้งานระบบฯ กับหน่วยงานที่จัดหลักสูตรการศึกษา เพื่อให้บริษัทสามารถพัฒนาระบบฯ ได้อย่างมีประสิทธิภาพและสอดคล้องกับความต้องการใช้งานจริง ของหน่วยผู้ใช้งาน ทั้งนี้ มอบหมายให้ พ.ท. ไชยยันต์ วงศาโรจน์ หน.เทคโนโลยีดิจิทัล กทด.บก.สปท. โทร.ทหาร 5031512 โทรศัพท์เคลื่อนที่ 08 5112 3644 เป็นผู้ประสานในรายละเอียด\n",
    "\"\"\"\n",
    "\n",
    "summary = strong_summarize(your_text)\n",
    "print(\"📄 Summary:\\n\", summary)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dt1mPqrTCqEa",
    "outputId": "0ff7d459-fc72-40b2-bf19-e10b4af08c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.1.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_0Xx5YMC0rp",
    "outputId": "845f7389-f290-4ff3-e7e1-90a179a4c322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9ce3fbad50fadd4bd97199052dbb86087f8fe8cda96ade67e28b01322f605370\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "93524f8d78b34284afeffdfacaa753f6",
      "8c0671ddc6134efca01302641dee03aa",
      "3fb533ac271245d1ac060f17413f425a",
      "b5dcbce3096b45de88dfa7085b637325",
      "43501c8afb1e4b5193cdba8ac345b05f",
      "b74d5292b48e4d08b073ae167d2c5100",
      "2cd807fc36754b09b37d8f8260db0e90",
      "df1b27c780ae499d8c32d566842c6a88",
      "084accd24c8a45b6aa533f31a2a0984f",
      "fb96317e7f9a4822a9042468d0684898",
      "ac146f6a16c64627ba6e982cae60da1f"
     ]
    },
    "id": "ArYP0Dtv65Ef",
    "outputId": "d100c1d7-4733-45cd-8b36-b118d280ef8f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93524f8d78b34284afeffdfacaa753f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.4836\n",
      "ROUGE-2: 0.3827\n",
      "ROUGE-L: 0.4866\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from evaluate import load\n",
    "\n",
    "# Load metric\n",
    "rouge_metric = load(\"rouge\")\n",
    "\n",
    "# Evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Generate function\n",
    "def generate_summary_eval(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=512,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    batch[\"preds\"] = preds\n",
    "    return batch\n",
    "\n",
    "# Generate predictions\n",
    "predictions = tokenized_datasets[\"test\"].map(generate_summary_eval, batched=False)\n",
    "\n",
    "# Prepare predictions and references\n",
    "pred_texts = [str(p) for p in predictions[\"preds\"]]\n",
    "ref_texts = [str(r) for r in predictions[\"summary\"]]  # Just normal list of strings\n",
    "\n",
    "## 📋 Calculate ROUGE\n",
    "result = rouge_metric.compute(\n",
    "    predictions=pred_texts,\n",
    "    references=ref_texts,\n",
    "    use_stemmer=True\n",
    ")\n",
    "\n",
    "# ✅ Correct print format for new evaluate\n",
    "print(f\"ROUGE-1: {result['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {result['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {result['rougeL']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77A6D35s0eTk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
