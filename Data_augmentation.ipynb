{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swChnKRVWXu-",
        "outputId": "e26edea4-d4c6-4848-9339-08ff3631e617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Augmentation Complete. Total records: 150\n",
            "ðŸ“‚ Saved to: ./formal_thai_augmented.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Load your cleaned data\n",
        "file_path = \"./formal_thai.csv\"  # <-- Adjust your path if needed\n",
        "df = pd.read_csv(file_path, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Keep only valid rows\n",
        "df_clean = df.dropna(subset=[\"text\", \"summary\"]).reset_index(drop=True)\n",
        "\n",
        "# Rephrasing templates\n",
        "rephrasing_templates = [\n",
        "    \"à¸‚à¸­à¹€à¸£à¸µà¸¢à¸™à¹€à¸Šà¸´à¸à¸£à¹ˆà¸§à¸¡ \",\n",
        "    \"à¸¡à¸µà¹à¸œà¸™à¸ˆà¸°à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£ \",\n",
        "    \"à¸à¸³à¸«à¸™à¸”à¸ˆà¸±à¸” \",\n",
        "    \"à¹€à¸žà¸·à¹ˆà¸­à¸žà¸´à¸ˆà¸²à¸£à¸“à¸²à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š \",\n",
        "    \"à¹„à¸”à¹‰à¸à¹à¸²à¸«à¸™à¸”à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸¸à¸¡à¹€à¸žà¸·à¹ˆà¸­ \",\n",
        "    \"à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¹€à¸„à¸²à¸£à¸ž à¸‚à¸­à¹€à¸Šà¸´à¸à¹€à¸‚à¹‰à¸²à¸£à¹ˆà¸§à¸¡ \"\n",
        "]\n",
        "\n",
        "# Augmentation function\n",
        "def augment_text(text):\n",
        "    prefix = random.choice(rephrasing_templates)\n",
        "    return prefix + text\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "# Start augmenting\n",
        "for idx, row in df_clean.iterrows():\n",
        "    # 1. Original\n",
        "    augmented_rows.append({\n",
        "        \"text\": row[\"text\"],\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "    # 2. Rephrased\n",
        "    augmented_rows.append({\n",
        "        \"text\": augment_text(row[\"text\"]),\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "    # 3. Focused Short Version (keep first 25 words)\n",
        "    short_text = ' '.join(row[\"text\"].split()[:25]) + \"...\"\n",
        "    augmented_rows.append({\n",
        "        \"text\": \"à¸ªà¸£à¸¸à¸›à¸¢à¹ˆà¸­: \" + short_text,\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "# Create new DataFrame\n",
        "df_augmented = pd.DataFrame(augmented_rows)\n",
        "\n",
        "# Save augmented dataset\n",
        "augmented_file_path = \"./formal_thai_augmented.csv\"\n",
        "df_augmented.to_csv(augmented_file_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"âœ… Augmentation Complete. Total records: {len(df_augmented)}\")\n",
        "print(f\"ðŸ“‚ Saved to: {augmented_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Simple Thai rephrasing templates\n",
        "def augment_text(text):\n",
        "    patterns = [\n",
        "        \"à¸‚à¸­à¹€à¸£à¸µà¸¢à¸™à¹€à¸Šà¸´à¸à¸£à¹ˆà¸§à¸¡\",\n",
        "        \"à¸¡à¸µà¸à¸²à¸£à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢à¹€à¸žà¸·à¹ˆà¸­\",\n",
        "        \"à¸à¸³à¸«à¸™à¸”à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸¸à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š\",\n",
        "        \"à¹€à¸žà¸·à¹ˆà¸­à¸žà¸´à¸ˆà¸²à¸£à¸“à¸²à¹€à¸£à¸·à¹ˆà¸­à¸‡\",\n",
        "        \"à¸à¸³à¸«à¸™à¸”à¸žà¸´à¸˜à¸µà¸à¸²à¸£à¹ƒà¸™à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸‚à¸­à¸‡\",\n",
        "        \"à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¹€à¸„à¸²à¸£à¸žà¸‚à¸­à¹€à¸Šà¸´à¸à¹€à¸‚à¹‰à¸²à¸£à¹ˆà¸§à¸¡\"\n",
        "    ]\n",
        "    # Randomly select a template\n",
        "    prefix = random.choice(patterns)\n",
        "\n",
        "    # Augment: Add a polite prefix before the first sentence\n",
        "    return prefix + \" \" + text\n",
        "\n",
        "# Augment the dataset\n",
        "augmented_rows = []\n",
        "\n",
        "for idx, row in df_clean.iterrows():\n",
        "    # 1. Original\n",
        "    augmented_rows.append({\n",
        "        \"text\": row[\"text\"],\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "    # 2. Light rephrase\n",
        "    augmented_rows.append({\n",
        "        \"text\": augment_text(row[\"text\"]),\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "    # 3. Focused version (cut long details)\n",
        "    short_text = row[\"text\"].split(' ', 20)  # Keep only first ~20 words\n",
        "    short_text = ' '.join(short_text) + \"...\"\n",
        "    augmented_rows.append({\n",
        "        \"text\": \"à¸ªà¸£à¸¸à¸›à¸¢à¹ˆà¸­: \" + short_text,\n",
        "        \"summary\": row[\"summary\"]\n",
        "    })\n",
        "\n",
        "# Create new DataFrame\n",
        "df_augmented = pd.DataFrame(augmented_rows)\n",
        "\n",
        "print(f\"âœ… After augmentation: {len(df_augmented)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc-yg-vsWlB5",
        "outputId": "2d3022ee-e99f-406c-98b0-ac2069c845f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… After augmentation: 150 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to new CSV\n",
        "df_augmented.to_csv(\"./formal_thai_augmented.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"âœ… Saved as: ./formal_thai_augmented.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K67WypgtWqCb",
        "outputId": "183fa40d-b969-4df8-e933-c3c5b11b1767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved as: ./formal_thai_augmented.csv\n"
          ]
        }
      ]
    }
  ]
}